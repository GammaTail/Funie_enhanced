{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78a5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 915/9604 -> saved pair #904\r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ==== SETTINGS ====\n",
    "video_path = 'data/A/vidd2.mp4'\n",
    "output_input_dir = 'output/paired/input'\n",
    "output_target_dir = 'output/paired/target'\n",
    "os.makedirs(output_input_dir, exist_ok=True)\n",
    "os.makedirs(output_target_dir, exist_ok=True)\n",
    "\n",
    "# ==== VIDEO SETUP ====\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Get total frame count\n",
    "frame_count = 0\n",
    "saved_frame_count = 0\n",
    "\n",
    "# CLAHE setup\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    # Skip first 10 frames\n",
    "    if frame_count <= 10:\n",
    "        continue\n",
    "\n",
    "    # === Show Progress ===\n",
    "    print(f\"Processing frame {frame_count}/{total_frames} -> saved pair #{saved_frame_count}\", end='\\r')\n",
    "\n",
    "    # Save original frame as \"noisy\" input\n",
    "    input_img_path = os.path.join(output_input_dir, f\"frame_{saved_frame_count:04d}.png\")\n",
    "    cv2.imwrite(input_img_path, frame)\n",
    "\n",
    "    # === Image Enhancement Pipeline ===\n",
    "\n",
    "    ycrcb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
    "    ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\n",
    "    equalized_img = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "    ycrcb = cv2.cvtColor(equalized_img, cv2.COLOR_BGR2YCrCb)\n",
    "    ycrcb[:, :, 0] = clahe.apply(ycrcb[:, :, 0])\n",
    "    clahe_img = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "    clahe_img = clahe_img.astype(np.int16)\n",
    "    clahe_img = np.clip(clahe_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Save enhanced image as target\n",
    "    target_img_path = os.path.join(output_target_dir, f\"frame_{saved_frame_count:04d}.png\")\n",
    "    cv2.imwrite(target_img_path, clahe_img)\n",
    "\n",
    "    saved_frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"\\n✅ Finished: Saved {saved_frame_count} paired frames to '{output_input_dir}' and '{output_target_dir}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa309460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 921/7614 -> saved pair #910\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m     processed_bgr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(processed_bgr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint16), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     64\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_target_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msaved_frame_count\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_bgr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     saved_frame_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     69\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ==== SETTINGS ====\n",
    "video_path = 'data/A/vidd.mp4'  # Input video\n",
    "output_input_dir = 'output/paired/input'   # Save original frames here\n",
    "output_target_dir = 'output/paired/target'  # Save enhanced frames here\n",
    "\n",
    "os.makedirs(output_input_dir, exist_ok=True)\n",
    "os.makedirs(output_target_dir, exist_ok=True)\n",
    "\n",
    "# ==== VIDEO SETUP ====\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 0\n",
    "saved_frame_count = 0\n",
    "\n",
    "# ==== Enhancer Setup ====\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "denoise_kernel_size = 5  # Set to 0 or 1 to disable\n",
    "kernel_sharpen = np.array([[0, -1, 0],\n",
    "                           [-1,  5, -1],\n",
    "                           [0, -1, 0]])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "\n",
    "    # Skip first 10 frames if needed\n",
    "    if frame_count <= 10:\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing frame {frame_count}/{total_frames} -> saved pair #{saved_frame_count}\", end='\\r')\n",
    "\n",
    "    # ==== Save Original Frame ====\n",
    "    input_path = os.path.join(output_input_dir, f\"frame_{saved_frame_count:04d}.png\")\n",
    "    cv2.imwrite(input_path, frame)\n",
    "\n",
    "    # ==== Enhancement Pipeline ====\n",
    "    img_yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(img_yuv)\n",
    "\n",
    "    # CLAHE on luminance\n",
    "    y_clahe = clahe.apply(y)\n",
    "\n",
    "    # Optional denoising\n",
    "    y_processed = y_clahe\n",
    "    if denoise_kernel_size > 1 and denoise_kernel_size % 2 == 1:\n",
    "        y_denoised = cv2.GaussianBlur(y_clahe, (denoise_kernel_size, denoise_kernel_size), 0)\n",
    "        y_processed = y_denoised\n",
    "\n",
    "    # Sharpening\n",
    "    y_sharp = cv2.filter2D(y_processed, -1, kernel_sharpen)\n",
    "\n",
    "    # Merge and convert back\n",
    "    processed_yuv = cv2.merge([y_sharp, cr, cb])\n",
    "    processed_bgr = cv2.cvtColor(processed_yuv, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "    # Clip & Save Output\n",
    "    processed_bgr = np.clip(processed_bgr.astype(np.int16), 0, 255).astype(np.uint8)\n",
    "    output_path = os.path.join(output_target_dir, f\"frame_{saved_frame_count:04d}.png\")\n",
    "    cv2.imwrite(output_path, processed_bgr)\n",
    "\n",
    "    saved_frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"\\n✅ Finished: Saved {saved_frame_count} paired frames to:\")\n",
    "print(f\"  Input:  '{output_input_dir}'\")\n",
    "print(f\"  Target: '{output_target_dir}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pix2pix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
